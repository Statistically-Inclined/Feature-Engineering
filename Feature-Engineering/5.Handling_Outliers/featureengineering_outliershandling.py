# -*- coding: utf-8 -*-
"""FeatureEngineering-OutliersHandling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pNqUXwGcGko0PKEZA16BnEu-R4ziSTux
"""

import pandas as pd
import seaborn as sns

df=pd.read_csv('titanic.csv')
df.head()

df['Age'].isnull().sum()

sns.distplot(df['Age'].dropna())

sns.distplot(df['Age'].fillna(100))

"""1. FOR GAUSSIAN DISTRIBUTED """

figure=df.Age.hist(bins=50)
figure.set_title('Age')
figure.set_xlabel('Age')
figure.set_ylabel('No of passenger')

figure = df.boxplot(column="Age")

df['Age'].describe()

# Assuming Age follows A Gaussian Distribution we will calculate the boundaries which differentiates the outliers
upper_boundary = df['Age'].mean() + 3* df['Age'].std()
lower_boundary = df['Age'].mean() - 3* df['Age'].std()
print(lower_boundary)
print(upper_boundary)
print(df['Age'].mean())

data = df.copy()
data.loc[data['Age']>=73,'Age'] = 73

figure=data.Age.hist(bins=50)
figure.set_title('AGE')
figure.set_xlabel('AGE')
figure.set_ylabel('No of passenger')

"""FOR SKEWED FEATURE"""

figure=df.Fare.hist(bins=50)
figure.set_title('Fare')
figure.set_xlabel('Fare')
figure.set_ylabel('No of passenger')

df.boxplot(column="Fare")

df['Fare'].describe()

# Lets compute the Interquantile range to calculate the boundaries
IQR = df.Fare.quantile(0.75)-df.Fare.quantile(0.25)

lower_bridge = df['Fare'].quantile(0.25) - (IQR*1.5)
upper_bridge = df['Fare'].quantile(0.75) + (IQR*1.5)
print(lower_bridge) 
print(upper_bridge)

#### Extreme outliers
lower_bridge = df['Fare'].quantile(0.25) - (IQR*3)
upper_bridge = df['Fare'].quantile(0.75) + (IQR*3)
print(lower_bridge)
print(upper_bridge)

data = df.copy()

data.loc[data['Fare']>=100,'Fare'] = 100

figure=data.Fare.hist(bins=50)
figure.set_title('Fare')
figure.set_xlabel('Fare')
figure.set_ylabel('No of passenger')

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(data[['Age','Fare']].fillna(0),data['Survived'],test_size=0.3)

### Logistic Regression
from sklearn.linear_model import LogisticRegression
classifier=LogisticRegression()
classifier.fit(X_train,y_train)
y_pred=classifier.predict(X_test)
y_pred1=classifier.predict_proba(X_test)

from sklearn.metrics import accuracy_score,roc_auc_score
print("Accuracy_score: {}".format(accuracy_score(y_test,y_pred)))
print("roc_auc_score: {}".format(roc_auc_score(y_test,y_pred1[:,1])))

